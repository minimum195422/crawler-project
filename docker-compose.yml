version: '3.8'

x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: Dockerfile
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    - AIRFLOW__CORE__FERNET_KEY=
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
    - AIRFLOW__CORE__ENABLE_XCOM_PICKLING=True
    - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    - AIRFLOW__WEBSERVER__WORKERS=1
    - AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL=60
    # AWS credentials - for S3 integration
    - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
    - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
    - AWS_REGION=${AWS_REGION:-ap-southeast-1}
    - S3_BUCKET_NAME=${S3_BUCKET_NAME:-ecommerce-crawler-data}
  volumes:
    - ./:/app
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/logs:/opt/airflow/logs
    - ./data:/app/data
    - ./logs:/app/logs
    - ./config:/app/config
  networks:
    - ecommerce-crawler-network
  depends_on:
    - postgres

services:
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    networks:
      - ecommerce-crawler-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  airflow-init:
    <<: *airflow-common
    command: >
      bash -c "
        airflow db init &&
        airflow users create
          --username admin
          --password admin
          --firstname Admin
          --lastname User
          --role Admin
          --email admin@example.com
      "
    restart: on-failure

  # Standalone service for running the crawler manually if needed
  crawler:
    <<: *airflow-common
    profiles:
      - manual
    command: bash
    tty: true
    stdin_open: true

networks:
  ecommerce-crawler-network:
    driver: bridge

volumes:
  postgres-db-volume: